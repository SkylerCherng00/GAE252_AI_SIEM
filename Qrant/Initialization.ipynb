{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3920ced",
   "metadata": {},
   "source": [
    "# Lab: Create Qdrant (a vector database)\n",
    "## Vector\n",
    "- Sparse Vector: eg. one-hot encoding ç·¨ç¢¼ categorical data\n",
    "  - è©å½™é‡å¢åŠ  => ç¶­åº¦å¢åŠ \n",
    "- Dense Vecotr: æ–¼ NLP çš„æ‡‰ç”¨\n",
    "  - é€™äº›å‘é‡èƒ½å¤ æ•ç²å–®è©çš„èªç¾©ï¼Œä¸¦ä¸”å°‡èªç¾©ç›¸è¿‘çš„å–®è©æŠ•å½±åˆ°åµŒå…¥ç©ºé–“ä¸­çš„ç›¸è¿‘ä½ç½®\n",
    "  - å¯ä»¥æ•ç²å–®è©ä¹‹é–“çš„ç›¸é—œæ€§\n",
    "- Co-occurrence: å…±ç¾æˆ–å…±ç¾æ˜¯æ–‡æœ¬èªæ–™åº«ä¸­å…©å€‹ç›¸é„°è¡“èªæœ‰åºå‡ºç¾çš„é«˜æ©Ÿç‡é »ç‡\n",
    "  - æ‰¾åˆ°èªæ„ç›¸ä¼¼\n",
    "- Cosine metrics: åˆ¤æ–·ç›¸ä¼¼æ€§ï¼Œ2 vectors å¤¾è§’ cos å€¼è¶Šæ¥è¿‘ 1 è¶Šç›¸ä¼¼ (0: 90åº¦ ç¨ç«‹)\n",
    "  - Cosine distance: 0 è¡¨ç¤ºå®Œå…¨ç›¸åŒ, 2 è¡¨ç¤ºå®Œå…¨ä¸åŒ\n",
    "    - Cosine distance(A,B) = 1 - Cosine Similarity(A,B)\n",
    "\n",
    "## Qdrant é‡è¦åè©\n",
    "- Collectionsï¼ˆé›†åˆï¼‰ï¼šé›†åˆæ˜¯å¸¶æœ‰åç¨±çš„ä¸€å † pointsï¼ˆé™„å¸¶ payload çš„å‘é‡ï¼‰ï¼Œå¯ä»¥åœ¨å…¶ä¸­é€²è¡Œæœç´¢ã€‚å¯ä»¥æƒ³åƒæˆå‚³çµ±è³‡æ–™åº«çš„ table\n",
    "- Payloadï¼šç”¨ä¾†èˆ‡å‘é‡ä¸€èµ·å„²å­˜é¡å¤–çš„è³‡è¨Šï¼Œå°±æ˜¯ metadata çš„æ¦‚å¿µ\n",
    "- Pointï¼šPoint æ˜¯ Qdrant å„²å­˜è³‡æ–™çš„æ ¸å¿ƒå¯¦é«”ã€‚ä¸€å€‹é»æ˜¯ç”±å‘é‡å’Œ Payload æ‰€çµ„æˆçš„\n",
    "\n",
    "## Qdrant vector database\n",
    "- `docker-compose.yml`:\n",
    "```\n",
    "services:\n",
    "  qdrant:\n",
    "    image: qdrant/qdrant:latest\n",
    "    restart: always\n",
    "    ports:\n",
    "      - '6333:6333'\n",
    "    volumes: # local:docker\n",
    "      - ./qdrant_storage:/qdrant/storage\n",
    "```\n",
    "- ä½¿ç”¨æŒ‡ä»¤ `sudo docker compose up -d` -d: run background (read `docker-compose.yml` on the folder automatically)\n",
    "- é€²åˆ° http://localhost:6333/ æª¢æŸ¥ \n",
    "\n",
    "- å®‰è£ Qdrant çš„ Python SDK\n",
    "- ä½¿ç”¨æŒ‡ä»¤ `poetry add qdrant-client`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e46ea9",
   "metadata": {},
   "source": [
    "# Lab: qdrant_tutorial\n",
    "- `poetry add qdrant-client`\n",
    "- `http://<ip>:6333/dashboard` æŸ¥çœ‹è³‡æ–™åº«\n",
    "- CRUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abec9386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Qdrant collection\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "\n",
    "# Localhost example\n",
    "# client = QdrantClient(\"localhost\", port=6333)\n",
    "\n",
    "# Cloud example\n",
    "client = QdrantClient(\n",
    "    url=\"https://eeaa6571-6f65-4174-a647-9091668bb8c0.us-west-1-0.aws.cloud.qdrant.io:6333\", \n",
    "    api_key=\"\",\n",
    ")\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"test\",\n",
    "    vectors_config=models.VectorParams(size=3, distance=models.Distance.COSINE), # size: vector ç¶­åº¦\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4fc78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate collection (table)\n",
    "client.recreate_collection(\n",
    "    collection_name=\"test\",\n",
    "    vectors_config=models.VectorParams(size=3, distance=models.Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894fcf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete collection\n",
    "client.delete_collection(collection_name=\"test\")\n",
    "\n",
    "# æ³¨æ„è¦ 1.7 ä¹‹å¾Œçš„ qdrant æ‰æ”¯æ´ collection_exists method\n",
    "if not client.collection_exists(collection_name=\"test\"):\n",
    "    client.create_collection(\n",
    "        collection_name=\"test\",\n",
    "        vectors_config=models.VectorParams(size=3, distance=models.Distance.COSINE),\n",
    "    )\n",
    "    print(\"Not exisit, collection created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0681dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsert (insert) æ’å…¥ä¸€å€‹é»ä½ (point)\n",
    "client.upsert(\n",
    "    collection_name=\"test\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=\"5c56c793-69f3-4fbf-87e6-c4bf54c28c26\", # uuid\n",
    "            payload={\n",
    "                \"color\": \"red\", # metadata\n",
    "            },\n",
    "            vector=[0.9, 0.1, 0.1], # word vector\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078cbc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update æ›´æ–°å‘é‡\n",
    "client.update_vectors(\n",
    "    collection_name=\"test\",\n",
    "    points=[\n",
    "        models.PointVectors(\n",
    "            id=\"5c56c793-69f3-4fbf-87e6-c4bf54c28c26\",\n",
    "            vector=[0.9, 0.9, 0.9],\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af0c82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete point åˆªé™¤ç‰¹å®š point\n",
    "client.delete(\n",
    "    collection_name=\"test\",\n",
    "    points_selector=models.PointIdsList(\n",
    "        points=[\"5c56c793-69f3-4fbf-87e6-c4bf54c28c26\"],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0492af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_payload æ›´æ–° payload (metadata)\n",
    "client.set_payload(\n",
    "    collection_name=\"test\",\n",
    "    payload={\n",
    "        \"property1\": \"string\",\n",
    "        \"property2\": \"string\",\n",
    "    },\n",
    "    points=[\"5c56c793-69f3-4fbf-87e6-c4bf54c28c26\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5037ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite_payload è¤‡å¯« payload\n",
    "client.overwrite_payload(\n",
    "    collection_name=\"test\",\n",
    "    payload={\n",
    "        \"property1\": \"string\",\n",
    "        \"property2\": \"string\",\n",
    "    },\n",
    "    points=[\"5c56c793-69f3-4fbf-87e6-c4bf54c28c26\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fca252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete_payload åˆªé™¤ payload æŒ‡å®š key\n",
    "client.delete_payload(\n",
    "    collection_name=\"test\",\n",
    "    keys=[\"property2\"],\n",
    "    points=[\"5c56c793-69f3-4fbf-87e6-c4bf54c28c26\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018a897e",
   "metadata": {},
   "source": [
    "# LangChain æ•´åˆ Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b1f193d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Hello, can you introduce yourself?\n",
      "Response: Hello there! ğŸ‘‹\n",
      "\n",
      "I'm Gemma, a large language model created by the Gemma team at Google DeepMind. I'm an open-weights AI assistant, which means I'm available for anyone to use and build upon! \n",
      "\n",
      "I'm designed to take text and image as inputs and generate text as output. Basically, I can help with a lot of different things â€“ from writing stories and poems to answering questions and summarizing information. \n",
      "\n",
      "I'm still under development, but I'm learning new things every day. I'm excited to see what people will create with me! ğŸ˜Š\n",
      "\n",
      "\n",
      "\n",
      "Do you have any questions for me? I'd love to chat!\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Connect to Ollama Gemma LLM using LangChain\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# Initialize the Ollama LLM with your deployed Gemma model\n",
    "ollama_llm = OllamaLLM(\n",
    "    base_url=\"http://192.168.72.20:11434\",  # Your Ollama server URL\n",
    "    model=\"gemma3n:e2b\",  # Model name (adjust if your model has a different name)\n",
    "    temperature=0.7,  # Adjust temperature for creativity (0.0 to 1.0)\n",
    ")\n",
    "\n",
    "# Test the connection with a simple query\n",
    "test_query = \"Hello, can you introduce yourself?\"\n",
    "response = ollama_llm.invoke(test_query)\n",
    "print(f\"Query: {test_query}\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405b4315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'_id': '685d4d4d-6989-4f3b-8a72-f004e19f4e97', '_collection_name': 'test'}, page_content='è€Œæˆ‘ï¼Œåœ¨é€™åº§åŸå¸‚éºå¤±äº†ä½ ï¼Œé †ä¾¿éºå¤±äº†è‡ªå·±ï¼Œä»¥ç‚ºè’å”åˆ°åº•æœƒæœ‰æ·å¾‘ã€‚è€Œæˆ‘ï¼Œåœ¨é€™åº§åŸå¸‚å¤±å»äº†ä½ ï¼Œè¼¸çµ¦æ…¾æœ›é«˜æ¼²çš„è‡ªå·±ï¼Œä¸æ˜¯ä½ ï¼Œéåˆ†çš„æ„Ÿæƒ…')]\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨ Langchain çš„ Qdrant å¥—ä»¶è™•è£¡æ–‡å­—å‘é‡\n",
    "from langchain_community.vectorstores import Qdrant # <--\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings_model = OllamaEmbeddings(\n",
    "    base_url=\"http://192.168.72.20:11434\",\n",
    "    model=\"nomic-embed-text:v1.5\",\n",
    ")\n",
    "\n",
    "\n",
    "data_objs = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"lyric\": \"æˆ‘æœƒæŠ«æ˜Ÿæˆ´æœˆçš„æƒ³ä½ ï¼Œæˆ‘æœƒå¥®ä¸é¡§èº«çš„å‰é€²ï¼Œé æ–¹ç…™ç«è¶Šä¾†è¶Šå”å™“ï¼Œå‡è¦–å‰æ–¹èº«å¾Œçš„è·é›¢\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"lyric\": \"è€Œæˆ‘ï¼Œåœ¨é€™åº§åŸå¸‚éºå¤±äº†ä½ ï¼Œé †ä¾¿éºå¤±äº†è‡ªå·±ï¼Œä»¥ç‚ºè’å”åˆ°åº•æœƒæœ‰æ·å¾‘ã€‚è€Œæˆ‘ï¼Œåœ¨é€™åº§åŸå¸‚å¤±å»äº†ä½ ï¼Œè¼¸çµ¦æ…¾æœ›é«˜æ¼²çš„è‡ªå·±ï¼Œä¸æ˜¯ä½ ï¼Œéåˆ†çš„æ„Ÿæƒ…\"\n",
    "    }\n",
    "]\n",
    "\n",
    "lyric_list = [data_obj[\"lyric\"] for data_obj in data_objs]\n",
    "\n",
    "qdrant = Qdrant.from_texts(\n",
    "    lyric_list,  # list contained lyric\n",
    "    embeddings_model,  # model\n",
    "    url=\"https://eeaa6571-6f65-4174-a647-9091668bb8c0.us-west-1-0.aws.cloud.qdrant.io:6333\",\n",
    "    collection_name=\"test\",\n",
    "    force_recreate=True,\n",
    "    api_key=\"\",\n",
    ")\n",
    "\n",
    "output = qdrant.similarity_search(query=\"å·¥ç¨‹å¸«å¯«åŸå¸‚\", k=1, )\n",
    "# output = qdrant.similarity_search(query=\"æˆ‘é›¢ä½ æ„ˆä¾†æ„ˆé \", k=1, )\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3ee6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The lyrics express a profound sense of loss, longing, and self-destruction. Here's a breakdown:\n",
      "\n",
      "* **Loss and Self-Loss:** The opening lines highlight a feeling of being lost in the city, and with that loss, the speaker has also lost themselves. This suggests a deep emotional void.\n",
      "* **The Illusion of Shortcuts:** The phrase \"ä»¥ç‚ºè’å”åˆ°åº•æœƒæœ‰æ·å¾‘\" (thought that absurdity would finally have shortcuts) indicates a desperate search for an easier way to cope with the pain, a futile attempt to avoid the difficulty of dealing with the loss.\n",
      "* **Defeat to Desire:** The speaker admits to losing the relationship (represented by \"ä½ \" - you) not to fate, but to their own overwhelming desires and \"éåˆ†çš„æ„Ÿæƒ…\" (excessive emotion). This implies a self-inflicted wound, a surrender to their own feelings.\n",
      "* **Persistent Longing and Determination:** Despite the pain, the speaker vows to continue longing for the person (\"æˆ‘æœƒæŠ«æ˜Ÿæˆ´æœˆçš„æƒ³ä½ \") and to move forward with unwavering determination (\"æˆ‘æœƒå¥®ä¸é¡§èº«çš„å‰é€²\"). This shows resilience, but also a lingering sadness.\n",
      "* **Distance and Separation:** The final lines depict a growing distance, both physically and emotionally. The \"é æ–¹ç…™ç«è¶Šä¾†è¶Šå”å™“\" (distant fireworks are becoming increasingly melancholic) suggests a fading hope or a bittersweet memory. The \"å‡è¦–å‰æ–¹èº«å¾Œçš„è·é›¢\" (gazing at the distance between the front and back) emphasizes the feeling of being pulled apart and the difficulty of moving on.\n",
      "\n",
      "**Overall, the lyrics paint a picture of someone struggling with the consequences of their own desires, grappling with the pain of loss, and desperately trying to find a way to move forward despite the lingering sadness and distance.** The tone is melancholic, introspective, and filled with a sense of yearning. It's a powerful expression of heartbreak and the difficult path to healing.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Source documents: 2 documents found\n"
     ]
    }
   ],
   "source": [
    "# Advanced usage: Combine Ollama LLM with Qdrant for RAG (Retrieval Augmented Generation)\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# Initialize Ollama embeddings (you can use a different model for embeddings)\n",
    "ollama_embeddings = OllamaEmbeddings(\n",
    "    base_url=\"http://192.168.72.20:11434\",\n",
    "    model=\"gemma3n\",  # Or use a different model optimized for embeddings if available\n",
    ")\n",
    "\n",
    "# Example: Using both Ollama LLM and Qdrant for document search and generation\n",
    "def search_and_generate(query, qdrant_store, llm):\n",
    "    \"\"\"\n",
    "    Search for relevant documents in Qdrant and generate an answer using Ollama LLM\n",
    "    \"\"\"\n",
    "    # Search for similar documents\n",
    "    similar_docs = qdrant_store.similarity_search(query, k=3)\n",
    "    \n",
    "    # Combine the found documents as context\n",
    "    context = \"\\n\".join([doc.page_content for doc in similar_docs])\n",
    "    \n",
    "    # Create a prompt with context\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following context, please answer the question:\n",
    "    \n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question: {query}\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate response using Ollama LLM\n",
    "    response = llm.invoke(prompt)\n",
    "    return response, similar_docs\n",
    "\n",
    "# Example usage (uncomment when you have a Qdrant store ready)\n",
    "query = \"Tell me about the lyrics\"\n",
    "qdrant = Qdrant.from_texts(\n",
    "    lyric_list,  # list contained lyric\n",
    "    embeddings_model,  # model\n",
    "    url=\"https://eeaa6571-6f65-4174-a647-9091668bb8c0.us-west-1-0.aws.cloud.qdrant.io:6333\",\n",
    "    collection_name=\"test\",\n",
    "    force_recreate=True,\n",
    "    api_key=\"\",\n",
    ")\n",
    "\n",
    "ollama_llm = OllamaLLM(\n",
    "    base_url=\"http://192.168.72.20:11434\",  # Your Ollama server URL\n",
    "    model=\"gemma3n:e2b\",  # Model name (adjust if your model has a different name)\n",
    "    temperature=0.7,  # Adjust temperature for creativity (0.0 to 1.0)\n",
    ")\n",
    "\n",
    "answer, docs = search_and_generate(query, qdrant, ollama_llm)\n",
    "print(f\"Answer: {answer}\")\n",
    "print(f\"Source documents: {len(docs)} documents found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
