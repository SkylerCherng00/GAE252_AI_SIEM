{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3920ced",
   "metadata": {},
   "source": [
    "# Lab: Create Qdrant (a vector database)\n",
    "## Vector\n",
    "- Sparse Vector: eg. one-hot encoding 編碼 categorical data\n",
    "  - 詞彙量增加 => 維度增加\n",
    "- Dense Vecotr: 於 NLP 的應用\n",
    "  - 這些向量能夠捕獲單詞的語義，並且將語義相近的單詞投影到嵌入空間中的相近位置\n",
    "  - 可以捕獲單詞之間的相關性\n",
    "- Co-occurrence: 共現或共現是文本語料庫中兩個相鄰術語有序出現的高機率頻率\n",
    "  - 找到語意相似\n",
    "- Cosine metrics: 判斷相似性，2 vectors 夾角 cos 值越接近 1 越相似 (0: 90度 獨立)\n",
    "  - Cosine distance: 0 表示完全相同, 2 表示完全不同\n",
    "    - Cosine distance(A,B) = 1 - Cosine Similarity(A,B)\n",
    "\n",
    "## Qdrant 重要名詞\n",
    "- Collections（集合）：集合是帶有名稱的一堆 points（附帶 payload 的向量），可以在其中進行搜索。可以想像成傳統資料庫的 table\n",
    "- Payload：用來與向量一起儲存額外的資訊，就是 metadata 的概念\n",
    "- Point：Point 是 Qdrant 儲存資料的核心實體。一個點是由向量和 Payload 所組成的\n",
    "\n",
    "## Qdrant vector database\n",
    "- `docker-compose.yml`:\n",
    "```\n",
    "services:\n",
    "  qdrant:\n",
    "    image: qdrant/qdrant:latest\n",
    "    restart: always\n",
    "    ports:\n",
    "      - '6333:6333'\n",
    "    volumes: # local:docker\n",
    "      - ./qdrant_storage:/qdrant/storage\n",
    "```\n",
    "- 使用指令 `sudo docker compose up -d` -d: run background (read `docker-compose.yml` on the folder automatically)\n",
    "- 進到 http://localhost:6333/ 檢查 \n",
    "\n",
    "- 安裝 Qdrant 的 Python SDK\n",
    "- 使用指令 `poetry add qdrant-client`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e46ea9",
   "metadata": {},
   "source": [
    "# Lab: qdrant_tutorial\n",
    "- `poetry add qdrant-client`\n",
    "- `http://<ip>:6333/dashboard` 查看資料庫\n",
    "- CRUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abec9386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Qdrant collection\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "\n",
    "# Localhost example\n",
    "# client = QdrantClient(\"localhost\", port=6333)\n",
    "\n",
    "# Cloud example\n",
    "client = QdrantClient(\n",
    "    url=\"https://eeaa6571-6f65-4174-a647-9091668bb8c0.us-west-1-0.aws.cloud.qdrant.io:6333\", \n",
    "    api_key=\"\",\n",
    ")\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"test\",\n",
    "    vectors_config=models.VectorParams(size=3, distance=models.Distance.COSINE), # size: vector 維度\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4fc78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate collection (table)\n",
    "client.recreate_collection(\n",
    "    collection_name=\"test\",\n",
    "    vectors_config=models.VectorParams(size=3, distance=models.Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894fcf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete collection\n",
    "client.delete_collection(collection_name=\"test\")\n",
    "\n",
    "# 注意要 1.7 之後的 qdrant 才支援 collection_exists method\n",
    "if not client.collection_exists(collection_name=\"test\"):\n",
    "    client.create_collection(\n",
    "        collection_name=\"test\",\n",
    "        vectors_config=models.VectorParams(size=3, distance=models.Distance.COSINE),\n",
    "    )\n",
    "    print(\"Not exisit, collection created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0681dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsert (insert) 插入一個點位 (point)\n",
    "client.upsert(\n",
    "    collection_name=\"test\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=\"5c56c793-69f3-4fbf-87e6-c4bf54c28c26\", # uuid\n",
    "            payload={\n",
    "                \"color\": \"red\", # metadata\n",
    "            },\n",
    "            vector=[0.9, 0.1, 0.1], # word vector\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078cbc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update 更新向量\n",
    "client.update_vectors(\n",
    "    collection_name=\"test\",\n",
    "    points=[\n",
    "        models.PointVectors(\n",
    "            id=\"5c56c793-69f3-4fbf-87e6-c4bf54c28c26\",\n",
    "            vector=[0.9, 0.9, 0.9],\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af0c82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete point 刪除特定 point\n",
    "client.delete(\n",
    "    collection_name=\"test\",\n",
    "    points_selector=models.PointIdsList(\n",
    "        points=[\"5c56c793-69f3-4fbf-87e6-c4bf54c28c26\"],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0492af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_payload 更新 payload (metadata)\n",
    "client.set_payload(\n",
    "    collection_name=\"test\",\n",
    "    payload={\n",
    "        \"property1\": \"string\",\n",
    "        \"property2\": \"string\",\n",
    "    },\n",
    "    points=[\"5c56c793-69f3-4fbf-87e6-c4bf54c28c26\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5037ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite_payload 複寫 payload\n",
    "client.overwrite_payload(\n",
    "    collection_name=\"test\",\n",
    "    payload={\n",
    "        \"property1\": \"string\",\n",
    "        \"property2\": \"string\",\n",
    "    },\n",
    "    points=[\"5c56c793-69f3-4fbf-87e6-c4bf54c28c26\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fca252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete_payload 刪除 payload 指定 key\n",
    "client.delete_payload(\n",
    "    collection_name=\"test\",\n",
    "    keys=[\"property2\"],\n",
    "    points=[\"5c56c793-69f3-4fbf-87e6-c4bf54c28c26\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018a897e",
   "metadata": {},
   "source": [
    "# LangChain 整合 Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1f193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Ollama Gemma LLM using LangChain\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# Initialize the Ollama LLM with your deployed Gemma model\n",
    "ollama_llm = OllamaLLM(\n",
    "    base_url=\"http://192.168.72.20:11434\",  # Your Ollama server URL\n",
    "    model=\"gemma3n:e2b\",  # Model name (adjust if your model has a different name)\n",
    "    temperature=0.7,  # Adjust temperature for creativity (0.0 to 1.0)\n",
    ")\n",
    "\n",
    "# Test the connection with a simple query\n",
    "test_query = \"Hello, can you introduce yourself?\"\n",
    "response = ollama_llm.invoke(test_query)\n",
    "print(f\"Query: {test_query}\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405b4315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 Langchain 的 Qdrant 套件處裡文字向量\n",
    "from langchain_community.vectorstores import Qdrant # <--\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings_model = OllamaEmbeddings(\n",
    "    base_url=\"http://192.168.72.20:11434\",\n",
    "    model=\"nomic-embed-text:v1.5\",\n",
    ")\n",
    "\n",
    "\n",
    "data_objs = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"lyric\": \"我會披星戴月的想你，我會奮不顧身的前進，遠方煙火越來越唏噓，凝視前方身後的距離\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"lyric\": \"而我，在這座城市遺失了你，順便遺失了自己，以為荒唐到底會有捷徑。而我，在這座城市失去了你，輸給慾望高漲的自己，不是你，過分的感情\"\n",
    "    }\n",
    "]\n",
    "\n",
    "lyric_list = [data_obj[\"lyric\"] for data_obj in data_objs]\n",
    "\n",
    "qdrant = Qdrant.from_texts(\n",
    "    lyric_list,  # list contained lyric\n",
    "    embeddings_model,  # model\n",
    "    url=\"https://eeaa6571-6f65-4174-a647-9091668bb8c0.us-west-1-0.aws.cloud.qdrant.io:6333\",\n",
    "    collection_name=\"test\",\n",
    "    force_recreate=True,\n",
    "    api_key=\"\",\n",
    ")\n",
    "\n",
    "output = qdrant.similarity_search(query=\"工程師寫城市\", k=1, )\n",
    "# output = qdrant.similarity_search(query=\"我離你愈來愈遠\", k=1, )\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3ee6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced usage: Combine Ollama LLM with Qdrant for RAG (Retrieval Augmented Generation)\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# Initialize Ollama embeddings (you can use a different model for embeddings)\n",
    "ollama_embeddings = OllamaEmbeddings(\n",
    "    base_url=\"http://192.168.72.20:11434\",\n",
    "    model=\"gemma3n\",  # Or use a different model optimized for embeddings if available\n",
    ")\n",
    "\n",
    "# Example: Using both Ollama LLM and Qdrant for document search and generation\n",
    "def search_and_generate(query, qdrant_store, llm):\n",
    "    \"\"\"\n",
    "    Search for relevant documents in Qdrant and generate an answer using Ollama LLM\n",
    "    \"\"\"\n",
    "    # Search for similar documents\n",
    "    similar_docs = qdrant_store.similarity_search(query, k=3)\n",
    "    \n",
    "    # Combine the found documents as context\n",
    "    context = \"\\n\".join([doc.page_content for doc in similar_docs])\n",
    "    \n",
    "    # Create a prompt with context\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following context, please answer the question:\n",
    "    \n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question: {query}\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate response using Ollama LLM\n",
    "    response = llm.invoke(prompt)\n",
    "    return response, similar_docs\n",
    "\n",
    "# Example usage (uncomment when you have a Qdrant store ready)\n",
    "query = \"Tell me about the lyrics\"\n",
    "qdrant = Qdrant.from_texts(\n",
    "    lyric_list,  # list contained lyric\n",
    "    embeddings_model,  # model\n",
    "    url=\"https://eeaa6571-6f65-4174-a647-9091668bb8c0.us-west-1-0.aws.cloud.qdrant.io:6333\",\n",
    "    collection_name=\"test\",\n",
    "    force_recreate=True,\n",
    "    api_key=\"\",\n",
    ")\n",
    "\n",
    "ollama_llm = OllamaLLM(\n",
    "    base_url=\"http://192.168.72.20:11434\",  # Your Ollama server URL\n",
    "    model=\"gemma3n:e2b\",  # Model name (adjust if your model has a different name)\n",
    "    temperature=0.7,  # Adjust temperature for creativity (0.0 to 1.0)\n",
    ")\n",
    "\n",
    "answer, docs = search_and_generate(query, qdrant, ollama_llm)\n",
    "print(f\"Answer: {answer}\")\n",
    "print(f\"Source documents: {len(docs)} documents found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
